{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16cf0e5e-370b-4a18-915e-1c5d0f2c1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_curve\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import torch\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cdd500-74a2-4950-9ea3-0b04bc67e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Player_ID              100000 non-null  int64  \n",
      " 1   Num_Sessions           100000 non-null  int64  \n",
      " 2   Avg_Session_Time       100000 non-null  int64  \n",
      " 3   Avg_Bet_Amount         100000 non-null  int64  \n",
      " 4   Num_Wins               100000 non-null  int64  \n",
      " 5   Num_Losses             100000 non-null  int64  \n",
      " 6   Total_Winnings         100000 non-null  float64\n",
      " 7   Total_Losses           100000 non-null  float64\n",
      " 8   Net_Profit             100000 non-null  float64\n",
      " 9   Favorite_Game          100000 non-null  object \n",
      " 10  Days_Since_Last_Play   100000 non-null  int64  \n",
      " 11  Player_Type            100000 non-null  object \n",
      " 12  Active_Days_Per_Month  100000 non-null  int64  \n",
      " 13  Used_Bonuses           100000 non-null  int64  \n",
      " 14  Total_Deposit          100000 non-null  float64\n",
      " 15  Total_Withdrawal       100000 non-null  float64\n",
      " 16  Avg_Reaction_Time      100000 non-null  float64\n",
      " 17  Trend_Sessions         100000 non-null  float64\n",
      " 18  Frustration_Score      100000 non-null  int64  \n",
      " 19  Churn                  100000 non-null  int64  \n",
      " 20  Soft_Churn             100000 non-null  int64  \n",
      "dtypes: float64(7), int64(12), object(2)\n",
      "memory usage: 16.0+ MB\n",
      "None\n",
      "Target variable distribution (Churn):\n",
      "Churn\n",
      "1    0.61088\n",
      "0    0.38912\n",
      "Name: proportion, dtype: float64\n",
      "Feature statistics:\n",
      "           Player_ID   Num_Sessions  Avg_Session_Time  Avg_Bet_Amount  \\\n",
      "count  100000.000000  100000.000000     100000.000000   100000.000000   \n",
      "mean    50000.500000      20.002650         91.991770       99.815650   \n",
      "std     28867.657797       4.482854         50.589859      232.212045   \n",
      "min         1.000000       4.000000          5.000000        5.000000   \n",
      "25%     25000.750000      17.000000         48.000000       10.000000   \n",
      "50%     50000.500000      20.000000         92.000000       20.000000   \n",
      "75%     75000.250000      23.000000        136.000000       50.000000   \n",
      "max    100000.000000      45.000000        179.000000     1000.000000   \n",
      "\n",
      "            Num_Wins     Num_Losses  Total_Winnings   Total_Losses  \\\n",
      "count  100000.000000  100000.000000   100000.000000  100000.000000   \n",
      "mean        5.128920      14.873730     1401.281199     994.056718   \n",
      "std         4.029246       5.042432     4433.208621    2372.191861   \n",
      "min         0.000000       1.000000        0.000000      13.332372   \n",
      "25%         2.000000      12.000000       28.933534     105.510290   \n",
      "50%         5.000000      15.000000       80.504252     244.251260   \n",
      "75%         7.000000      18.000000      294.503816     793.430443   \n",
      "max        35.000000      37.000000    55453.225526   35013.793881   \n",
      "\n",
      "          Net_Profit  Days_Since_Last_Play  Active_Days_Per_Month  \\\n",
      "count  100000.000000         100000.000000          100000.000000   \n",
      "mean     -407.224481             29.454240               9.258740   \n",
      "std      3694.123654             17.372577               3.723892   \n",
      "min    -52856.566840              0.000000               1.000000   \n",
      "25%        18.404609             14.000000               7.000000   \n",
      "50%        94.199620             29.000000               9.000000   \n",
      "75%       295.204926             45.000000              12.000000   \n",
      "max     29618.106747             59.000000              25.000000   \n",
      "\n",
      "        Used_Bonuses  Total_Deposit  Total_Withdrawal  Avg_Reaction_Time  \\\n",
      "count  100000.000000  100000.000000     100000.000000      100000.000000   \n",
      "mean        0.502460    5030.745881       3021.082282           2.749190   \n",
      "std         0.499996    2871.865007       1994.687604           1.302361   \n",
      "min         0.000000      50.070000         17.370000           0.500007   \n",
      "25%         0.000000    2545.755000       1385.892500           1.618984   \n",
      "50%         1.000000    5045.755000       2753.615000           2.744717   \n",
      "75%         1.000000    7520.235000       4356.517500           3.882434   \n",
      "max         1.000000    9999.760000       8983.260000           4.999983   \n",
      "\n",
      "       Trend_Sessions  Frustration_Score          Churn     Soft_Churn  \n",
      "count   100000.000000      100000.000000  100000.000000  100000.000000  \n",
      "mean        -0.000050           1.523210       0.610880       0.059760  \n",
      "std          6.328027           0.529211       0.487553       0.237043  \n",
      "min        -33.000000           0.000000       0.000000       0.000000  \n",
      "25%         -4.000000           1.000000       0.000000       0.000000  \n",
      "50%          0.000000           2.000000       1.000000       0.000000  \n",
      "75%          4.000000           2.000000       1.000000       0.000000  \n",
      "max         28.000000           3.000000       1.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Memory cleanup\n",
    "gc.collect()\n",
    "\n",
    "# Load data\n",
    "casino_data = pd.read_csv(\"casino_players_data.csv\")\n",
    "\n",
    "# **Dataset Analysis**\n",
    "print(\"Basic dataset information:\")\n",
    "print(casino_data.info())\n",
    "print(\"Target variable distribution (Churn):\")\n",
    "print(casino_data[\"Churn\"].value_counts(normalize=True))\n",
    "print(\"Feature statistics:\")\n",
    "print(casino_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284817db-5f06-43be-9edf-cb2ef9c2100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to numerical values\n",
    "encoder = LabelEncoder()\n",
    "for col in [\"Favorite_Game\", \"Player_Type\"]:\n",
    "    if col in casino_data.columns:\n",
    "        casino_data[col] = encoder.fit_transform(casino_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80bac63c-68f6-4446-870d-b09ef0aeff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features\n",
    "corr_matrix = casino_data.corr()\n",
    "high_corr_features = set()\n",
    "threshold_corr = 0.9  # Correlation threshold\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > threshold_corr:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            high_corr_features.add(colname)\n",
    "\n",
    "casino_data = casino_data.drop(columns=high_corr_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65600ec-b776-4bee-829d-dd73235051c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = casino_data.drop(columns=[col for col in [\"Churn\", \"Player_ID\"] if col in casino_data.columns])\n",
    "y = casino_data[\"Churn\"]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a4b350a-5c11-4ea4-a3f7-2a8d339194ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available - training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Detect GPU availability for model training\n",
    "gpu_available = torch.cuda.is_available()\n",
    "if gpu_available:\n",
    "    print(\"GPU available - enabling GPU support for models!\")\n",
    "else:\n",
    "    print(\"GPU not available - training on CPU.\")\n",
    "\n",
    "# **Train initial RandomForest model for feature selection**\n",
    "rf_initial = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\n",
    "rf_initial.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# **Select important features based on RandomForest model**\n",
    "def select_important_features(model, X, threshold=0.01):\n",
    "    feature_importances = model.feature_importances_\n",
    "    important_features = [X.columns[i] for i in range(len(feature_importances)) if feature_importances[i] > threshold]\n",
    "    return X[important_features]\n",
    "\n",
    "\n",
    "X_train = select_important_features(rf_initial, X_train)\n",
    "X_test = X_test[X_train.columns]  # Remove the same features from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "977fc860-834e-4715-b3b0-389ca8a243b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=150, max_depth=10, min_samples_split=5, class_weight='balanced',\n",
    "                                           random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": xgb.XGBClassifier(n_estimators=150, max_depth=6, reg_lambda=1.5, reg_alpha=0.5,\n",
    "                                 eval_metric='logloss', verbosity=1),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(n_estimators=150, max_depth=6, lambda_l1=1.0, lambda_l2=1.0, verbose=1),\n",
    "    \"CatBoost\": cb.CatBoostClassifier(n_estimators=150, depth=6, l2_leaf_reg=1.5, verbose=1,\n",
    "                                      task_type='GPU' if gpu_available else 'CPU'),\n",
    "    \"LogisticRegression\": LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b54aef5-e6b5-4b8d-8da3-2342232fb92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model RandomForest...\n",
      "Model RandomForest training completed.\n",
      "Training model XGBoost...\n",
      "Model XGBoost training completed.\n",
      "Training model LightGBM...\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] Number of positive: 48818, number of negative: 31182\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 607\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.610225 -> initscore=0.448258\n",
      "[LightGBM] [Info] Start training from score 0.448258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model LightGBM training completed.\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Training model CatBoost...\n",
      "0:\tlearn: 0.6641608\ttotal: 8.09ms\tremaining: 1.2s\n",
      "1:\tlearn: 0.6367535\ttotal: 16.4ms\tremaining: 1.21s\n",
      "2:\tlearn: 0.6108978\ttotal: 24.8ms\tremaining: 1.21s\n",
      "3:\tlearn: 0.5865213\ttotal: 33.2ms\tremaining: 1.21s\n",
      "4:\tlearn: 0.5634171\ttotal: 41.4ms\tremaining: 1.2s\n",
      "5:\tlearn: 0.5415120\ttotal: 50.3ms\tremaining: 1.21s\n",
      "6:\tlearn: 0.5207697\ttotal: 59.7ms\tremaining: 1.22s\n",
      "7:\tlearn: 0.5010953\ttotal: 69.1ms\tremaining: 1.23s\n",
      "8:\tlearn: 0.4823860\ttotal: 78.4ms\tremaining: 1.23s\n",
      "9:\tlearn: 0.4645616\ttotal: 87.4ms\tremaining: 1.22s\n",
      "10:\tlearn: 0.4475797\ttotal: 95.2ms\tremaining: 1.2s\n",
      "11:\tlearn: 0.4313481\ttotal: 103ms\tremaining: 1.19s\n",
      "12:\tlearn: 0.4158256\ttotal: 113ms\tremaining: 1.19s\n",
      "13:\tlearn: 0.4010622\ttotal: 122ms\tremaining: 1.18s\n",
      "14:\tlearn: 0.3869044\ttotal: 129ms\tremaining: 1.16s\n",
      "15:\tlearn: 0.3733552\ttotal: 138ms\tremaining: 1.15s\n",
      "16:\tlearn: 0.3604009\ttotal: 146ms\tremaining: 1.14s\n",
      "17:\tlearn: 0.3479688\ttotal: 155ms\tremaining: 1.14s\n",
      "18:\tlearn: 0.3360966\ttotal: 163ms\tremaining: 1.13s\n",
      "19:\tlearn: 0.3246774\ttotal: 172ms\tremaining: 1.12s\n",
      "20:\tlearn: 0.3137910\ttotal: 181ms\tremaining: 1.11s\n",
      "21:\tlearn: 0.3033371\ttotal: 191ms\tremaining: 1.11s\n",
      "22:\tlearn: 0.2933496\ttotal: 200ms\tremaining: 1.1s\n",
      "23:\tlearn: 0.2836622\ttotal: 208ms\tremaining: 1.09s\n",
      "24:\tlearn: 0.2743821\ttotal: 218ms\tremaining: 1.09s\n",
      "25:\tlearn: 0.2654671\ttotal: 224ms\tremaining: 1.07s\n",
      "26:\tlearn: 0.2568587\ttotal: 235ms\tremaining: 1.07s\n",
      "27:\tlearn: 0.2486030\ttotal: 243ms\tremaining: 1.06s\n",
      "28:\tlearn: 0.2406580\ttotal: 251ms\tremaining: 1.05s\n",
      "29:\tlearn: 0.2330346\ttotal: 260ms\tremaining: 1.04s\n",
      "30:\tlearn: 0.2256875\ttotal: 269ms\tremaining: 1.03s\n",
      "31:\tlearn: 0.2186283\ttotal: 280ms\tremaining: 1.03s\n",
      "32:\tlearn: 0.2118403\ttotal: 287ms\tremaining: 1.02s\n",
      "33:\tlearn: 0.2052889\ttotal: 297ms\tremaining: 1.01s\n",
      "34:\tlearn: 0.1989462\ttotal: 308ms\tremaining: 1.01s\n",
      "35:\tlearn: 0.1928460\ttotal: 318ms\tremaining: 1s\n",
      "36:\tlearn: 0.1869480\ttotal: 331ms\tremaining: 1.01s\n",
      "37:\tlearn: 0.1812424\ttotal: 344ms\tremaining: 1.01s\n",
      "38:\tlearn: 0.1757351\ttotal: 356ms\tremaining: 1.01s\n",
      "39:\tlearn: 0.1703984\ttotal: 369ms\tremaining: 1.01s\n",
      "40:\tlearn: 0.1652772\ttotal: 384ms\tremaining: 1.02s\n",
      "41:\tlearn: 0.1603530\ttotal: 393ms\tremaining: 1.01s\n",
      "42:\tlearn: 0.1556288\ttotal: 407ms\tremaining: 1.01s\n",
      "43:\tlearn: 0.1510838\ttotal: 422ms\tremaining: 1.02s\n",
      "44:\tlearn: 0.1466857\ttotal: 435ms\tremaining: 1.01s\n",
      "45:\tlearn: 0.1424321\ttotal: 448ms\tremaining: 1.01s\n",
      "46:\tlearn: 0.1382590\ttotal: 460ms\tremaining: 1.01s\n",
      "47:\tlearn: 0.1342356\ttotal: 471ms\tremaining: 1s\n",
      "48:\tlearn: 0.1303444\ttotal: 482ms\tremaining: 994ms\n",
      "49:\tlearn: 0.1265744\ttotal: 495ms\tremaining: 989ms\n",
      "50:\tlearn: 0.1230013\ttotal: 508ms\tremaining: 986ms\n",
      "51:\tlearn: 0.1195539\ttotal: 519ms\tremaining: 977ms\n",
      "52:\tlearn: 0.1162183\ttotal: 530ms\tremaining: 970ms\n",
      "53:\tlearn: 0.1129653\ttotal: 586ms\tremaining: 1.04s\n",
      "54:\tlearn: 0.1098155\ttotal: 608ms\tremaining: 1.05s\n",
      "55:\tlearn: 0.1067577\ttotal: 617ms\tremaining: 1.03s\n",
      "56:\tlearn: 0.1038146\ttotal: 633ms\tremaining: 1.03s\n",
      "57:\tlearn: 0.1009355\ttotal: 644ms\tremaining: 1.02s\n",
      "58:\tlearn: 0.0981553\ttotal: 653ms\tremaining: 1.01s\n",
      "59:\tlearn: 0.0954636\ttotal: 662ms\tremaining: 993ms\n",
      "60:\tlearn: 0.0928549\ttotal: 672ms\tremaining: 980ms\n",
      "61:\tlearn: 0.0903535\ttotal: 683ms\tremaining: 970ms\n",
      "62:\tlearn: 0.0879670\ttotal: 693ms\tremaining: 957ms\n",
      "63:\tlearn: 0.0856436\ttotal: 703ms\tremaining: 944ms\n",
      "64:\tlearn: 0.0833484\ttotal: 713ms\tremaining: 932ms\n",
      "65:\tlearn: 0.0811592\ttotal: 722ms\tremaining: 919ms\n",
      "66:\tlearn: 0.0790485\ttotal: 731ms\tremaining: 906ms\n",
      "67:\tlearn: 0.0770287\ttotal: 740ms\tremaining: 893ms\n",
      "68:\tlearn: 0.0750985\ttotal: 749ms\tremaining: 879ms\n",
      "69:\tlearn: 0.0731261\ttotal: 758ms\tremaining: 866ms\n",
      "70:\tlearn: 0.0711822\ttotal: 768ms\tremaining: 854ms\n",
      "71:\tlearn: 0.0693482\ttotal: 777ms\tremaining: 842ms\n",
      "72:\tlearn: 0.0675894\ttotal: 789ms\tremaining: 833ms\n",
      "73:\tlearn: 0.0658736\ttotal: 802ms\tremaining: 823ms\n",
      "74:\tlearn: 0.0642229\ttotal: 812ms\tremaining: 812ms\n",
      "75:\tlearn: 0.0626055\ttotal: 823ms\tremaining: 801ms\n",
      "76:\tlearn: 0.0610343\ttotal: 833ms\tremaining: 790ms\n",
      "77:\tlearn: 0.0595199\ttotal: 846ms\tremaining: 781ms\n",
      "78:\tlearn: 0.0580697\ttotal: 857ms\tremaining: 770ms\n",
      "79:\tlearn: 0.0566449\ttotal: 869ms\tremaining: 761ms\n",
      "80:\tlearn: 0.0552539\ttotal: 883ms\tremaining: 752ms\n",
      "81:\tlearn: 0.0539327\ttotal: 897ms\tremaining: 744ms\n",
      "82:\tlearn: 0.0526547\ttotal: 912ms\tremaining: 736ms\n",
      "83:\tlearn: 0.0513876\ttotal: 928ms\tremaining: 729ms\n",
      "84:\tlearn: 0.0501889\ttotal: 945ms\tremaining: 723ms\n",
      "85:\tlearn: 0.0489867\ttotal: 961ms\tremaining: 715ms\n",
      "86:\tlearn: 0.0478672\ttotal: 975ms\tremaining: 706ms\n",
      "87:\tlearn: 0.0467648\ttotal: 991ms\tremaining: 698ms\n",
      "88:\tlearn: 0.0456834\ttotal: 1.01s\tremaining: 692ms\n",
      "89:\tlearn: 0.0446423\ttotal: 1.03s\tremaining: 685ms\n",
      "90:\tlearn: 0.0436806\ttotal: 1.04s\tremaining: 676ms\n",
      "91:\tlearn: 0.0427078\ttotal: 1.06s\tremaining: 666ms\n",
      "92:\tlearn: 0.0417174\ttotal: 1.07s\tremaining: 654ms\n",
      "93:\tlearn: 0.0407974\ttotal: 1.08s\tremaining: 643ms\n",
      "94:\tlearn: 0.0399099\ttotal: 1.09s\tremaining: 633ms\n",
      "95:\tlearn: 0.0390324\ttotal: 1.11s\tremaining: 623ms\n",
      "96:\tlearn: 0.0381956\ttotal: 1.12s\tremaining: 614ms\n",
      "97:\tlearn: 0.0373795\ttotal: 1.14s\tremaining: 604ms\n",
      "98:\tlearn: 0.0365844\ttotal: 1.15s\tremaining: 594ms\n",
      "99:\tlearn: 0.0357917\ttotal: 1.17s\tremaining: 583ms\n",
      "100:\tlearn: 0.0350515\ttotal: 1.18s\tremaining: 572ms\n",
      "101:\tlearn: 0.0343174\ttotal: 1.2s\tremaining: 563ms\n",
      "102:\tlearn: 0.0336087\ttotal: 1.21s\tremaining: 553ms\n",
      "103:\tlearn: 0.0329406\ttotal: 1.23s\tremaining: 543ms\n",
      "104:\tlearn: 0.0322672\ttotal: 1.24s\tremaining: 532ms\n",
      "105:\tlearn: 0.0316360\ttotal: 1.26s\tremaining: 522ms\n",
      "106:\tlearn: 0.0310041\ttotal: 1.27s\tremaining: 511ms\n",
      "107:\tlearn: 0.0304127\ttotal: 1.28s\tremaining: 500ms\n",
      "108:\tlearn: 0.0298170\ttotal: 1.3s\tremaining: 489ms\n",
      "109:\tlearn: 0.0292468\ttotal: 1.31s\tremaining: 477ms\n",
      "110:\tlearn: 0.0287033\ttotal: 1.32s\tremaining: 466ms\n",
      "111:\tlearn: 0.0281564\ttotal: 1.34s\tremaining: 455ms\n",
      "112:\tlearn: 0.0276322\ttotal: 1.35s\tremaining: 444ms\n",
      "113:\tlearn: 0.0271417\ttotal: 1.37s\tremaining: 433ms\n",
      "114:\tlearn: 0.0266671\ttotal: 1.39s\tremaining: 424ms\n",
      "115:\tlearn: 0.0261607\ttotal: 1.41s\tremaining: 413ms\n",
      "116:\tlearn: 0.0257136\ttotal: 1.42s\tremaining: 401ms\n",
      "117:\tlearn: 0.0252763\ttotal: 1.44s\tremaining: 390ms\n",
      "118:\tlearn: 0.0248427\ttotal: 1.45s\tremaining: 378ms\n",
      "119:\tlearn: 0.0244172\ttotal: 1.47s\tremaining: 368ms\n",
      "120:\tlearn: 0.0240180\ttotal: 1.49s\tremaining: 357ms\n",
      "121:\tlearn: 0.0236338\ttotal: 1.5s\tremaining: 345ms\n",
      "122:\tlearn: 0.0232429\ttotal: 1.52s\tremaining: 333ms\n",
      "123:\tlearn: 0.0228688\ttotal: 1.53s\tremaining: 322ms\n",
      "124:\tlearn: 0.0225002\ttotal: 1.55s\tremaining: 310ms\n",
      "125:\tlearn: 0.0221752\ttotal: 1.57s\tremaining: 299ms\n",
      "126:\tlearn: 0.0218577\ttotal: 1.59s\tremaining: 288ms\n",
      "127:\tlearn: 0.0215382\ttotal: 1.6s\tremaining: 276ms\n",
      "128:\tlearn: 0.0212295\ttotal: 1.62s\tremaining: 264ms\n",
      "129:\tlearn: 0.0209168\ttotal: 1.64s\tremaining: 252ms\n",
      "130:\tlearn: 0.0206144\ttotal: 1.65s\tremaining: 240ms\n",
      "131:\tlearn: 0.0203179\ttotal: 1.67s\tremaining: 228ms\n",
      "132:\tlearn: 0.0200246\ttotal: 1.69s\tremaining: 215ms\n",
      "133:\tlearn: 0.0197481\ttotal: 1.7s\tremaining: 203ms\n",
      "134:\tlearn: 0.0194863\ttotal: 1.72s\tremaining: 191ms\n",
      "135:\tlearn: 0.0192249\ttotal: 1.74s\tremaining: 179ms\n",
      "136:\tlearn: 0.0189756\ttotal: 1.82s\tremaining: 173ms\n",
      "137:\tlearn: 0.0187607\ttotal: 1.85s\tremaining: 161ms\n",
      "138:\tlearn: 0.0185197\ttotal: 1.86s\tremaining: 148ms\n",
      "139:\tlearn: 0.0182875\ttotal: 1.88s\tremaining: 134ms\n",
      "140:\tlearn: 0.0180487\ttotal: 1.9s\tremaining: 121ms\n",
      "141:\tlearn: 0.0178235\ttotal: 1.91s\tremaining: 108ms\n",
      "142:\tlearn: 0.0176120\ttotal: 1.93s\tremaining: 94.5ms\n",
      "143:\tlearn: 0.0174212\ttotal: 1.95s\tremaining: 81.1ms\n",
      "144:\tlearn: 0.0172105\ttotal: 1.96s\tremaining: 67.7ms\n",
      "145:\tlearn: 0.0170134\ttotal: 1.98s\tremaining: 54.3ms\n",
      "146:\tlearn: 0.0168108\ttotal: 2s\tremaining: 40.8ms\n",
      "147:\tlearn: 0.0166209\ttotal: 2.02s\tremaining: 27.3ms\n",
      "148:\tlearn: 0.0164316\ttotal: 2.04s\tremaining: 13.7ms\n",
      "149:\tlearn: 0.0162559\ttotal: 2.06s\tremaining: 0us\n",
      "Model CatBoost training completed.\n",
      "Training model LogisticRegression...\n",
      "Model LogisticRegression training completed.\n",
      "                Model  Accuracy  Precision    Recall  F1-Score\n",
      "0        RandomForest   0.99460   0.999589  0.991606  0.995581\n",
      "1             XGBoost   0.99505   0.999098  0.992828  0.995953\n",
      "2            LightGBM   0.99490   0.999754  0.991932  0.995827\n",
      "3            CatBoost   0.99545   0.999508  0.993073  0.996280\n",
      "4  LogisticRegression   0.95610   0.997467  0.930807  0.962985\n"
     ]
    }
   ],
   "source": [
    "metrics_results = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training model {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Model {model_name} training completed.\")\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.8).astype(int)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    metrics_results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": report['1']['precision'],\n",
    "        \"Recall\": report['1']['recall'],\n",
    "        \"F1-Score\": report['1']['f1-score']\n",
    "    })\n",
    "\n",
    "    joblib.dump(model, f\"{model_name}.pkl\")\n",
    "\n",
    "# Create comparison table\n",
    "metrics_df = pd.DataFrame(metrics_results)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456e6397-554a-4932-9d2b-29417f4bd287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Save processed data to disk\n",
    "casino_data.to_csv(\"casino_players_data_processed.csv\", index=False)\n",
    "print(\"Data has been saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1594d-221c-4843-8a15-33f5a2018b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
